{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from scipy.spatial import distance\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, classes, overlap_thresh, num_boxes=20):\n",
    "    #print('Before NMD box shape', np.array(boxes).shape)\n",
    "    classes_set = np.unique(classes)\n",
    "    output_boxes = []\n",
    "    output_scores = []\n",
    "    output_classes = []\n",
    "    sort_by_score_idxs = np.argsort(scores)\n",
    "    boxes = np.array(boxes)[sort_by_score_idxs]\n",
    "    classes = np.array(classes)[sort_by_score_idxs]\n",
    "    scores = np.array(scores)[sort_by_score_idxs]\n",
    "    for cl in classes_set:\n",
    "        class_indices = np.where(cl == classes)\n",
    "        class_scores = scores[class_indices]\n",
    "        class_boxes = boxes[class_indices]\n",
    "        \n",
    "        x1 = class_boxes[:, 0]\n",
    "        y1 = class_boxes[:, 1]\n",
    "        x2 = class_boxes[:, 2]\n",
    "        y2 = class_boxes[:, 3]\n",
    "        \n",
    "        areas = np.abs(x2 - x1 + 1) * np.abs(y2 - y1 + 1)\n",
    "        available_indices = np.arange(class_scores.shape[0])\n",
    "        while available_indices.size > 0:\n",
    "            output_boxes.append(class_boxes[available_indices[-1]])\n",
    "            output_scores.append(class_scores[available_indices[-1]])\n",
    "            output_classes.append(cl)\n",
    "            if available_indices.size <= 1:\n",
    "                break\n",
    "            yy1 = np.maximum(y1[available_indices[-1]], y1[available_indices[:-1]])\n",
    "            xx1 = np.maximum(x1[available_indices[-1]], x1[available_indices[:-1]])\n",
    "            yy2 = np.minimum(y2[available_indices[-1]], y2[available_indices[:-1]])\n",
    "            xx2 = np.minimum(x2[available_indices[-1]], x2[available_indices[:-1]])\n",
    "            \n",
    "            w = np.maximum(0.0, xx2-xx1+1)\n",
    "            h = np.maximum(0.0, yy2-yy1+1)\n",
    "            intersection = w*h; \n",
    "\n",
    "            iou = 1.0*intersection/(areas[available_indices[:-1]] + areas[available_indices[-1]] - intersection)\n",
    "            suppressed_indices = available_indices[np.where(iou > overlap_thresh)]\n",
    "\n",
    "            available_indices = available_indices[np.where(iou <= overlap_thresh)]\n",
    "\n",
    "    sorted_idx = np.argsort(output_scores)[::-1]\n",
    "    output_boxes, output_scores, output_classes = np.array(output_boxes)[sorted_idx], np.array(output_scores)[sorted_idx], np.array(output_classes)[sorted_idx] \n",
    "    return (output_boxes[:num_boxes], output_scores[:num_boxes], output_classes[:num_boxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path_file):\n",
    "    with open(path_file) as file_ptr:\n",
    "        data = json.load(file_ptr)\n",
    "    return data\n",
    "def write_json(path_file, data):\n",
    "    with open(path_file, \"w\") as file_ptr:\n",
    "        json.dump(data, file_ptr, indent=4)\n",
    "\n",
    "class ImagePatcher():\n",
    "    '''\n",
    "    Assumes that the input images to the patcher will be of same size\n",
    "    '''\n",
    "    def __init__(self, patch_sz, overlap):\n",
    "        self.window_sz = patch_sz\n",
    "        self.overlap = overlap\n",
    "    \n",
    "    def calculate_padding_for_same_pad(self, input_sz, kernel_sz, stride):\n",
    "        '''\n",
    "        Calculate required padding such that kernel convolves on the\n",
    "        entire input\n",
    "        '''\n",
    "        output_sz = np.ceil(input_sz / stride)\n",
    "        total_pad = (output_sz - 1) * stride - input_sz + kernel_sz\n",
    "        \n",
    "        low_priority_pad = total_pad // 2\n",
    "        high_priority_pad = total_pad - low_priority_pad\n",
    "        return low_priority_pad, high_priority_pad\n",
    "    \n",
    "    def get_num_windows_along_axis(self, axis_len, window_len, overlap):\n",
    "        '''\n",
    "        Params:\n",
    "        ------\n",
    "        + axis_len - number of pixels along an axis of image\n",
    "        + window_len - number of pixels along an axis of window\n",
    "        + overlap - overlap between two windows in percentage\n",
    "        Returns:\n",
    "        -------\n",
    "        + number of windows along the axis\n",
    "        + stride - number of pixels for the jump\n",
    "        + number of pad with low priority (left pad along width, top pad along height)\n",
    "        + number of pad with high priority (right pad along width, bottom pad along height)\n",
    "        '''\n",
    "        stride = np.floor(window_len * (100 - overlap) * 0.01)\n",
    "        low_priority_pad, high_priority_pad = self.calculate_padding_for_same_pad(input_sz=axis_len, kernel_sz=window_len, stride=stride)\n",
    "        num_windows =int(((axis_len - window_len + low_priority_pad + high_priority_pad) // stride)) + 1    \n",
    "        return int(num_windows), int(stride), int(low_priority_pad), int(high_priority_pad)\n",
    "    \n",
    "    def is_inside_bbox(self, point, bbox):\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        point_x, point_y = point\n",
    "        return point_x >= xmin and point_x <= xmax and point_y >= ymin and point_y <= ymax\n",
    "    \n",
    "    def get_patch_annotations(self, patch_xmin, patch_xmax, patch_ymin, patch_ymax, annotations):\n",
    "        patch_bboxs = []\n",
    "        patch_box = (patch_xmin, patch_ymin, patch_xmax, patch_ymax)\n",
    "        for bbox in annotations:\n",
    "            xmin, ymin, xmax, ymax = bbox\n",
    "            xmin = xmin + self.left_pad\n",
    "            xmax = xmax + self.left_pad\n",
    "            ymin = ymin + self.top_pad\n",
    "            ymax = ymax + self.top_pad\n",
    "            \n",
    "            if self.is_inside_bbox(point=(xmin, ymin), bbox=patch_box) or \\\n",
    "               self.is_inside_bbox(point=(xmin, ymax), bbox=patch_box) or \\\n",
    "               self.is_inside_bbox(point=(xmax, ymin), bbox=patch_box) or \\\n",
    "               self.is_inside_bbox(point=(xmax, ymax), bbox=patch_box):\n",
    "                patch_bbox_xmin = max(xmin, patch_xmin) - patch_xmin\n",
    "                patch_bbox_ymin = max(ymin, patch_ymin) - patch_ymin\n",
    "                patch_bbox_xmax = min(xmax, patch_xmax) - patch_xmin\n",
    "                patch_bbox_ymax = min(ymax, patch_ymax) - patch_ymin\n",
    "                patch_bboxs.append([patch_bbox_xmin, patch_bbox_ymin, patch_bbox_xmax, patch_bbox_ymax])\n",
    "        return patch_bboxs\n",
    "\n",
    "    def generate_patches(self, path_img_file, path_json_file=None, path_patch_dir=\"dataset/patches/\"):\n",
    "        \"\"\"\n",
    "        Generate patches from image provided\n",
    "        \"\"\"\n",
    "        img = cv2.imread(path_img_file)\n",
    "        if path_json_file is not None:\n",
    "            annotations = read_json(path_json_file)\n",
    "\n",
    "        self.height, self.width, self.channels = img.shape\n",
    "        self.dtype = img.dtype\n",
    "        self.num_rows, self.row_stride, self.left_pad, self.right_pad = self.get_num_windows_along_axis(axis_len=self.height, window_len=self.window_sz,overlap=self.overlap)\n",
    "        self.num_cols, self.col_stride, self.top_pad, self.bottom_pad = self.get_num_windows_along_axis(axis_len=self.width, window_len=self.window_sz,overlap=self.overlap)\n",
    "        \n",
    "        self.padded_img_height = self.height+self.left_pad+self.right_pad\n",
    "        self.padded_img_width = self.width+self.top_pad+self.bottom_pad\n",
    "        padded_img = np.zeros(shape=(self.padded_img_height, self.padded_img_width, self.channels), dtype=self.dtype)\n",
    "        padded_img[self.left_pad:self.left_pad+self.height, self.right_pad:self.right_pad+self.width, :] = img\n",
    "        # cv2.imwrite(\"padded_img.png\", padded_img)\n",
    "\n",
    "        path_patch_dir = Path(path_patch_dir)\n",
    "        path_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "        image_filename = Path(path_img_file).stem\n",
    "\n",
    "        for row_idx in range(0, self.num_rows):\n",
    "            for col_idx in range(0, self.num_cols):\n",
    "                h_grid_start = row_idx * self.row_stride\n",
    "                w_grid_start = col_idx * self.col_stride\n",
    "                \n",
    "                patch_xmin = w_grid_start\n",
    "                patch_xmax = w_grid_start+self.window_sz\n",
    "                patch_ymin = h_grid_start\n",
    "                patch_ymax = h_grid_start+self.window_sz\n",
    "                \n",
    "                patch = padded_img[patch_ymin:patch_ymax, patch_xmin:patch_xmax, :] # slice \n",
    "                # print(\"patch sz\", patch.shape)\n",
    "                \n",
    "                patch_name = \"{}_{}_{}\".format(image_filename, row_idx, col_idx)\n",
    "                if path_json_file is not None:\n",
    "                    patch_bboxs = self.get_patch_annotations(patch_xmin, patch_xmax, patch_ymin, patch_ymax, annotations)\n",
    "                    # for patch_bbox in patch_bboxs:\n",
    "                    #     patch = cv2.rectangle(patch, (patch_bbox[0], patch_bbox[1]), (patch_bbox[2], patch_bbox[3]), (255, 255, 0), 1)\n",
    "                    write_json(path_file=\"{}/{}.json\".format(path_patch_dir, patch_name), data=patch_bboxs)\n",
    "                cv2.imwrite(\"{}/{}.jpg\".format(path_patch_dir, patch_name), patch)\n",
    "    \n",
    "    def generate_img_from_patches(self, path_patch_dir, img_name, score_threshold=0.0, path_annotation_dir=None):\n",
    "        padded_img = np.zeros(shape=(self.padded_img_height, self.padded_img_width, self.channels), dtype=self.dtype)\n",
    "        img_bboxs, scores, classes = [], [], []\n",
    "        for row_idx in range(0, self.num_rows):\n",
    "            for col_idx in range(0, self.num_cols):\n",
    "                h_grid_start = row_idx * self.row_stride\n",
    "                w_grid_start = col_idx * self.col_stride\n",
    "                \n",
    "                patch_xmin = w_grid_start\n",
    "                patch_xmax = w_grid_start+self.window_sz\n",
    "                patch_ymin = h_grid_start\n",
    "                patch_ymax = h_grid_start+self.window_sz\n",
    "                \n",
    "                patch_name = \"{}_{}_{}\".format(img_name, row_idx, col_idx)\n",
    "                patch = cv2.imread(\"{}/{}.jpg\".format(path_patch_dir, patch_name))\n",
    "                \n",
    "                padded_img[patch_ymin:patch_ymax, patch_xmin:patch_xmax, :] = patch\n",
    "                if path_annotation_dir is not None:\n",
    "                    patch_bboxs, _score, _classes = read_json(\"{}/{}.json\".format(path_annotation_dir, patch_name))\n",
    "                    for bbox, tmp_score, tmp_class in zip(patch_bboxs,_score, _classes):\n",
    "                        if tmp_score >= score_threshold:\n",
    "                            xmin, ymin, xmax, ymax = bbox\n",
    "                            xmin = max(xmin + patch_xmin - self.left_pad, 0)\n",
    "                            ymin = max(ymin + patch_ymin - self.top_pad, 0)\n",
    "                            xmax = min(xmax + patch_xmin - self.left_pad, self.width)\n",
    "                            ymax = min(ymax + patch_ymin - self.top_pad, self.height)\n",
    "                            img_bboxs.append([xmin, ymin, xmax, ymax])\n",
    "                            scores.append(tmp_score)\n",
    "                            classes.append(tmp_class)\n",
    "        \n",
    "        cv2.imwrite(\"./padded_img_from_patches_{}.png\".format(img_name), padded_img)\n",
    "        original_img = padded_img[self.left_pad:self.left_pad+self.height, self.right_pad:self.right_pad+self.width, :]\n",
    "        cv2.imwrite(\"./original_img_from_patches_{}.png\".format(img_name), np.copy(original_img))\n",
    "        if path_annotation_dir is not None:\n",
    "            mask = np.zeros_like(original_img)\n",
    "            # print(\"Before NMS\", len(img_bboxs))\n",
    "            img_bboxs, scores, _ = nms(boxes=np.array(img_bboxs), scores=np.array(scores), classes=np.array(classes), \n",
    "                                  overlap_thresh=0.001, num_boxes=None) # TODO: change overlap threshold\n",
    "            img_bboxs = img_bboxs.tolist()\n",
    "            print(\"Penguins after NMS:\", len(img_bboxs))\n",
    "            scores = scores.tolist()\n",
    "            for bbox in img_bboxs:\n",
    "                original_img = cv2.rectangle(original_img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "                mask = cv2.rectangle(mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), -1)\n",
    "            write_json(\"./original_img_bboxes_{}.json\".format(img_name), data = [img_bboxs, scores])\n",
    "            cv2.imwrite(\"PATH_TO_INFERENCE_RESULT\".format(img_name), original_img)\n",
    "            cv2.imwrite(\"PATH_TO_INFERENCE_MASK\".format(img_name), mask)\n",
    "            return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference_for_single_img(model, img, score_threshold):\n",
    "    bboxs, scores = [], []\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image = np.asarray(img)\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Do inference here\n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                     for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "   \n",
    "    # Filter bboxs \n",
    "    for bbox_normalised, score in zip(output_dict['detection_boxes'], output_dict['detection_scores']):\n",
    "        if score > score_threshold:\n",
    "            ymin, xmin, ymax, xmax = bbox_normalised\n",
    "            ymin = int(img.shape[0] * ymin)\n",
    "            xmin = int(img.shape[1] * xmin)\n",
    "            ymax = int(img.shape[0] * ymax)\n",
    "            xmax = int(img.shape[1] * xmax)\n",
    "            bboxs.append([xmin, ymin, xmax, ymax]) # bbox should be in [xmin, ymin, xmax, ymax]\n",
    "            scores.append(score)        \n",
    "    bboxs, scores, classes = nms(boxes=np.array(bboxs), scores=np.array(scores), \n",
    "                                 classes= np.array([0] * len(scores)), overlap_thresh=0.5, num_boxes=None)\n",
    "    return bboxs.tolist(), scores.tolist(), classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(model, path_img, score_threshold):\n",
    "    path_patch_dir = \"./tmp\"\n",
    "    img_name = Path(path_img).stem\n",
    "    image_patcher = ImagePatcher(patch_sz=224, overlap=25) # TODO: change patch size and overlap %\n",
    "    image_patcher.generate_patches(path_img_file=path_img, path_patch_dir=path_patch_dir)\n",
    "    \n",
    "    path_patch_imgs = list(glob.glob(\"{}/{}_*.jpg\".format(path_patch_dir, img_name)))\n",
    "    for path_patch_img in path_patch_imgs:\n",
    "        patch_img = cv2.imread(path_patch_img)\n",
    "        bboxs, score, classes = do_inference_for_single_img(model=model, img=patch_img, score_threshold=score_threshold)\n",
    "        write_json(path_file=path_patch_img.replace(\".jpg\", \".json\"), data=[bboxs, score, classes])\n",
    "\n",
    "    img_mask = image_patcher.generate_img_from_patches(path_patch_dir=path_patch_dir, \n",
    "                                                       img_name=img_name, \n",
    "                                                       score_threshold=score_threshold,\n",
    "                                                       path_annotation_dir=path_patch_dir)\n",
    "    img_mask = img_mask[:, :, 0]\n",
    "\n",
    "    # erode\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    erosion = cv2.erode(img_mask, kernel, iterations = 2)\n",
    "\n",
    "    cnts = cv2.findContours(erosion, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    num_penguins = len(cnts)\n",
    "    bbox_viz = cv2.drawContours(image=np.zeros(shape=(img_mask.shape[0], img_mask.shape[1], 3)), \n",
    "                                contours=cnts, contourIdx=-1, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.imwrite(\"PATH_TO_SAVE_CONTOURS\".format(img_name), img_mask)\n",
    "    img = cv2.imread(path_img)\n",
    "    img_viz = cv2.drawContours(image=img, contours=cnts, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.imwrite(\"PATH_TO_SAVE_CONTOURS\".format(img_name), img_viz)\n",
    "    print(\"[mask method]: Number of penguins in {} : {}\".format(img_name, num_penguins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED_MODEL = \"PATH_TO_SAVED_MODEL\" # Path to saved model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.saved_model.load(PATH_TO_SAVED_MODEL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Inferencing... ', end='')\n",
    "start_time = time.time()\n",
    "do_inference(model=model, path_img=\"TEST_IMAGE_PATH\", score_threshold=0.7) # TODO: Change score threshold, path to image1\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done inferencing! Took {} seconds'.format(elapsed_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
