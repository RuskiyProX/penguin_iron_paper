{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb38cb3-10b4-40a3-8cbc-59692a2640e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4cc3f-0a9a-4cc2-92a4-71a1d9cf8827",
   "metadata": {},
   "source": [
    "Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aa260-187a-4d63-b1f7-1d59cf2fa273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import imagecodecs\n",
    "import os\n",
    "import tifffile as tifi\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from scipy.spatial import distance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ead52-8b82-4775-bd7d-27ca0150d828",
   "metadata": {},
   "source": [
    "First, we need to preprocess the image we want to be inferenced by our model. After choosing the image, it is necessary to create small patches, which will be fed to the model. If the patch size is very big, the model may not detect properly all the objects, so just to assure the maximum efficiency, we will use the same patch size as the images we used for training the model: 224x224. \n",
    "\n",
    "To create patches of 224x224, our image must be dividable exactly by these dimensions. For instance, if our original image that we want to be patched is 3000 high and 4000 wide, we can not tile in equal patches without having extra pixel that can not form another patch of 224x224, i.e. 3000%224 is not 0, the same with 4000. \n",
    "\n",
    "In order to have a division with the reaminder = 0, we must either enlarge or shirnk our original image. To enlarge, we add to each dimension the difference between the patch size and the reminder. To shrink, we deduce the reminder from the original size. As our image has enough quality, we will use the enlargement process, expressed by the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a060f4-8373-4e6a-9764-a03f7dd91adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resizer():\n",
    "    def __init__(self, patch_sz):\n",
    "        self.patch_sz = patch_sz\n",
    "        \n",
    "    def get_correct_shape(self, orig_img_sz, patch_sz):\n",
    "        modified_img_sz = orig_img_sz # we assume that we got the correct image size\n",
    "        extra = orig_img_sz % patch_sz\n",
    "        if extra != 0:\n",
    "            #ENLARGING\n",
    "            modified_img_sz = (orig_img_sz + (patch_sz - extra))\n",
    "            #SHRINKING\n",
    "            #modified_img_sz = (orig_img_sz - extra)\n",
    "        return modified_img_sz\n",
    "\n",
    "    def resize(self, path_img_file, patch_sz):\n",
    "        #Modiffied this to read a large TIF file\n",
    "        image = tifi.imread(path_img_file)\n",
    "        img = image\n",
    "        #img = cv2.imread(path_img_file) # if color image, then 3D array\n",
    "        orig_img_sz = {\"W\":img.shape[1], \"H\":img.shape[0]}\n",
    "\n",
    "        # what if the image cannot be split into patches perfectly?\n",
    "        # original sz W - 3000, original H sz - 4000\n",
    "        # enlarging the image - (3000 + (224 - 88)) % 224\n",
    "        # shrinking the image - 3000 - 88\n",
    "        modified_img_sz = {} \n",
    "        modified_img_sz[\"H\"] = self.get_correct_shape(orig_img_sz=orig_img_sz[\"H\"], patch_sz=patch_sz[\"H\"]) \n",
    "        modified_img_sz[\"W\"] = self.get_correct_shape(orig_img_sz=orig_img_sz[\"W\"], patch_sz=patch_sz[\"W\"]) \n",
    "        # resize the image\n",
    "        #img = cv2.resize(img, (modified_img_sz[\"W\"], modified_img_sz[\"H\"]), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.resize(img, (modified_img_sz[\"W\"], modified_img_sz[\"H\"]), interpolation=cv2.INTER_CUBIC)\n",
    "        # save the resized image\n",
    "        cv2.imwrite(\"SAVE_PATH\", img)\n",
    "        \n",
    "patch_sz = {\"W\":416, \"H\":416} # This should be dependant on the model input\n",
    "path_img_file = \"PATH_IMAGE_TO_RESIZE\"\n",
    "patch_maker = Resizer(patch_sz)\n",
    "patch_maker.resize(path_img_file=path_img_file, patch_sz=patch_sz)\n",
    "print('Resized image created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08da96-3290-4cc3-ab91-8224f245c1d1",
   "metadata": {},
   "source": [
    "Then, after resizing the desired image accordingly, we are going to create the patches using the library patchify. Once the patches are created, we will save them into a folder. This is done by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b5083-afe0-4ff6-833f-6350972126ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagecodecs\n",
    "image = tifi.imread(\"PATH_RESIZED_IMAGE\")\n",
    "img = image\n",
    "#img = cv2.imread(\"PATH_RESIZED_IMAGE\")\n",
    "patches_img = patchify(img, (416,416,3), step=416)  # patches_img.shape = (14, 18, 1, 224, 224, 3)\n",
    "y = 0\n",
    "for i in range(patches_img.shape[0]):\n",
    "    for j in range(patches_img.shape[1]):\n",
    "        single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "        #cv2.rectangle(single_patch_img, (30, 30), (224-30, 224-30), (0, 255, 0), 3)  # Draw something (for testing).\n",
    "        # THIS CODE IS TO DRAW THE POINT IN THE MIDDLE OF THE IMAGE\n",
    "        c1 = (30+194)/2, (30+194)/2\n",
    "        c2 = (30+120)/2, (30+120)/2\n",
    "        rect1center = int(c1[0]), int(c1[1])\n",
    "        rect2center = int(c2[0]), int(c2[1])\n",
    "        # CODE TO GET THE EUCLIDEAN DISTANCE\n",
    "        dst = distance.euclidean(c1, c2)\n",
    "        #cv2.circle(single_patch_img, rect1center, radius=2, color=(255, 0, 0), thickness=3)\n",
    "        #cv2.circle(single_patch_img, rect2center, radius=2, color=(0,0, 255), thickness=3)\n",
    "        #ist = np.linalg.norm(c1-c2)\n",
    "        #print(dst)\n",
    "        if not cv2.imwrite('PATH_TO_SAVE_PATCHES' + 'image_1_' + str(y).zfill(5) + '.png', single_patch_img):  # Save as PNG, not JPEG for keeping the quality.\n",
    "            raise Exception(\"Could not write the image\")\n",
    "        y += 1\n",
    "\n",
    "num_patches = y\n",
    "\n",
    "# Store an unpatchified reference for testing\n",
    "#cv2.imwrite(\"unpatched_ref.jpg\", unpatchify(patches_img, img.shape))\n",
    "print('{} patches stored in the indicated path'.format(num_patches))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
